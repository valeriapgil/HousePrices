{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b031ad4-7f7a-4ec4-99bc-74fde8af6214",
   "metadata": {},
   "source": [
    "### Part 3: Obtaining and comparing predictions using the three models (BP, BP-F, MLR-F)\n",
    "First we'll make all the necessary imports needed in this part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d560be9b-377d-46f1-8639-85b983a1b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe7c4f-60db-4589-878a-bbbe07c45038",
   "metadata": {},
   "source": [
    "Then we make a function to calculate all the different metrics needed in this section. In this case, the metrics are:\n",
    "- MSE - Mean Squared Error\n",
    "- MAE - Mean Absolute Error\n",
    "- MAPE - Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e889c2d-d2fb-4d7c-b290-a96d15fa145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute MSE, MAE, and MAPE using scikit-learn.\n",
    "    Returns the three metrics as floats.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # convert to %\n",
    "    \n",
    "    return mse, mae, mape\n",
    "\n",
    "# True and predicted values for each model (TODO: these are examples, replace when we have the real data)\n",
    "\n",
    "# True values (zμ)\n",
    "z_test = np.array([10, 20, 30, 40, 50, 60])\n",
    "\n",
    "# Predicted values (yμ) from each model\n",
    "y_pred_mlr = np.array([11, 19, 29, 41, 49, 62])  # MLR-F\n",
    "y_pred_bp = np.array([12, 22, 33, 39, 52, 59])   # Custom BP\n",
    "y_pred_bpf = np.array([10, 20, 30, 40, 50, 61])  # BP-F (library)\n",
    "\n",
    "# Compute metrics for each model\n",
    "mse_mlr, mae_mlr, mape_mlr = evaluate_model(z_test, y_pred_mlr)\n",
    "mse_bp, mae_bp, mape_bp = evaluate_model(z_test, y_pred_bp)\n",
    "mse_bpf, mae_bpf, mape_bpf = evaluate_model(z_test, y_pred_bpf)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['MLR-F (Linear Regression)', 'BP (Custom NN)', 'BP-F (Library NN)'],\n",
    "    'MSE': [mse_mlr, mse_bp, mse_bpf],\n",
    "    'MAE': [mae_mlr, mae_bp, mae_bpf],\n",
    "    'MAPE (%)': [mape_mlr, mape_bp, mape_bpf]\n",
    "}).round(3)\n",
    "\n",
    "print(\"Evaluation Metrics for Each Model\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba946b9-623d-4843-a23f-7b0c16b4512d",
   "metadata": {},
   "source": [
    "Then we make the plots for the results that we got from the metrics. This allows us to see if our prediction is near the true values and know if our model is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2b383-d66e-4e11-8159-0cd135010675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Scatter plots yμ vs zμ\n",
    "\n",
    "models = {\n",
    "    'MLR-F (Linear Regression)': y_pred_mlr,\n",
    "    'BP (Custom NN)': y_pred_bp,\n",
    "    'BP-F (Library NN)': y_pred_bpf\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i, (name, y_pred) in enumerate(models.items()):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(z_test, y_pred, color='steelblue', edgecolors='k', alpha=0.75)\n",
    "    plt.plot([z_test.min(), z_test.max()], [z_test.min(), z_test.max()], 'r--', lw=2)\n",
    "    plt.title(f\"{name}\\nPredicted vs Real Values\")\n",
    "    plt.xlabel(\"Real Values (zμ)\")\n",
    "    plt.ylabel(\"Predicted Values (yμ)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle(\"Comparison of Model Predictions\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
