{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b031ad4-7f7a-4ec4-99bc-74fde8af6214",
   "metadata": {},
   "source": [
    "### Part 3: Obtaining and comparing predictions using the three models (BP, BP-F, MLR-F)\n",
    "The first step is make all the necessary imports needed for the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d560be9b-377d-46f1-8639-85b983a1b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from NeuralNet import NeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe7c4f-60db-4589-878a-bbbe07c45038",
   "metadata": {},
   "source": [
    "#### MSE, MAE and MAPE\n",
    "Then we make a function to calculate all the different metrics needed in this section. In this case, the metrics are:\n",
    "- MSE - Mean Squared Error\n",
    "- MAE - Mean Absolute Error\n",
    "- MAPE - Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b413a-1a3b-4ec0-91d1-50912a48149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute MSE, MAE, and MAPE using scikit-learn.\n",
    "    Returns the three metrics as floats.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # convert to %\n",
    "    \n",
    "    return mse, mae, mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27880573-6cd0-4039-a41b-de1606bbcc90",
   "metadata": {},
   "source": [
    "#### Denormalize function\n",
    "The denormalize function will be called every time that we obtain the predictions of the model. This way, the predictions are stored directly denormalized. When doing all the plots, the real values will be denormalized as well with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e889c2d-d2fb-4d7c-b290-a96d15fa145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59582292 0.5187076  0.63866476 ... 0.76147804 0.40624777 0.42159943]\n",
      "Epoch 0/150 - Training Error: 0.027675 - Validation Error: 0.024433\n",
      "Epoch 100/150 - Training Error: 0.003339 - Validation Error: 0.003442\n",
      "Epoch 0/200 - Training Error: 0.013710 - Validation Error: 0.010894\n",
      "Epoch 100/200 - Training Error: 0.003480 - Validation Error: 0.004783\n",
      "Epoch 0/250 - Training Error: 0.013455 - Validation Error: 0.010362\n",
      "Epoch 100/250 - Training Error: 0.002903 - Validation Error: 0.002627\n",
      "Epoch 200/250 - Training Error: 0.002438 - Validation Error: 0.002534\n",
      "Epoch 0/200 - Training Error: 0.026240 - Validation Error: 0.023720\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    115\u001b[39m nn_model = NeuralNet(layers = params[\u001b[33m'\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m'\u001b[39m], epochs = params[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m], learning_rate = params[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m], momentum = params[\u001b[33m'\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    116\u001b[39m     function = params[\u001b[33m'\u001b[39m\u001b[33mactivation\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    117\u001b[39m     validation_split = \u001b[32m0.2\u001b[39m\n\u001b[32m    118\u001b[39m )\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mnn_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m pred_train_bp_scaled = nn_model.predict(X_train)\n\u001b[32m    123\u001b[39m pred_test_bp_scaled  = nn_model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\mas\\NEC\\NeuralNet.py:103\u001b[39m, in \u001b[36mNeuralNet.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    101\u001b[39m   \u001b[38;5;28mself\u001b[39m.feed_foward(x_patron)\n\u001b[32m    102\u001b[39m   \u001b[38;5;28mself\u001b[39m.back_propagation_errors(y_patron)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_weights_and_thresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m train_error = \u001b[38;5;28mself\u001b[39m.mean_squared_error(X_train, y_train)\n\u001b[32m    106\u001b[39m val_error = \u001b[38;5;28mself\u001b[39m.mean_squared_error(X_val, y_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\mas\\NEC\\NeuralNet.py:136\u001b[39m, in \u001b[36mNeuralNet.update_weights_and_thresholds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_weights_and_thresholds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    135\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m lay \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.L):\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28mself\u001b[39m.d_w[lay] = -\u001b[38;5;28mself\u001b[39m.learning_rate * \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlay\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlay\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.momentum * \u001b[38;5;28mself\u001b[39m.d_w_prev[lay]\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m.d_w_prev[lay] = \u001b[38;5;28mself\u001b[39m.d_w[lay]\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m.w[lay] += \u001b[38;5;28mself\u001b[39m.d_w[lay]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\mas\\Lib\\site-packages\\numpy\\_core\\numeric.py:961\u001b[39m, in \u001b[36mouter\u001b[39m\u001b[34m(a, b, out)\u001b[39m\n\u001b[32m    959\u001b[39m a = asarray(a)\n\u001b[32m    960\u001b[39m b = asarray(b)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def denormalize(arr_scaled, col='SalePrice'):\n",
    "    \"\"\"\n",
    "    Inverse transform matching normalization:\n",
    "    scaled = 0.1 + 0.8 * (orig - abs_min) / (abs_max - abs_min)\n",
    "    so inverse: orig = abs_min + (scaled - 0.1)/0.8 * (abs_max - abs_min)\n",
    "    \"\"\"\n",
    "    mn, mx = min_max[col]\n",
    "    arr_scaled = np.asarray(arr_scaled).ravel()\n",
    "    return mn + (arr_scaled - 0.1) / 0.8 * (mx - mn)\n",
    "\n",
    "df = pd.read_csv('data_clean.csv')\n",
    "df = df.select_dtypes(include = ['float64', 'int64'])\n",
    "\n",
    "#store the min and the max of each column to denormalize the data later\n",
    "min_max = {}\n",
    "for column in df.columns:\n",
    "    min_max[column] = [df[column].abs().min(), df[column].abs().max()]\n",
    "\n",
    "# normalize all the data of the dataframe between 0 and 1\n",
    "df_scaled = df.copy()\n",
    "\n",
    "#normalize the data between 0 and 1 using the min_max dictionary\n",
    "for column in df_scaled.columns:\n",
    "    df_scaled[column] = 0.1 + 0.8 * (df_scaled[column] - min_max[column][0]) / (min_max[column][1] - min_max[column][0])\n",
    "\n",
    "y = df_scaled['SalePrice'].values\n",
    "X = df_scaled.drop('SalePrice', axis=1).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y)\n",
    "\n",
    "# Definition of hyperparameters including L2 regularization and dropout\n",
    "hyperparams = [\n",
    "    # Baseline Models (No Regularization)\n",
    "    {'layers':[X_train.shape[1], 8, 1], 'activation':'relu',\n",
    "     'lr':0.01, 'momentum':0.0, 'epochs':150,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.0},\n",
    "\n",
    "    {'layers':[X_train.shape[1], 8, 1], 'activation':'tanh',\n",
    "     'lr':0.01, 'momentum':0.9, 'epochs':200,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.0},\n",
    "\n",
    "    {'layers':[X_train.shape[1], 16, 8, 1], 'activation':'relu',\n",
    "     'lr':0.005, 'momentum':0.8, 'epochs':250,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.0},\n",
    "\n",
    "    # L2 Regularization\n",
    "    {'layers':[X_train.shape[1], 16, 1], 'activation':'sigmoid',\n",
    "     'lr':0.01, 'momentum':0.8, 'epochs':200,\n",
    "     'weight_decay':0.0005, 'dropout_rate':0.0},   # Mild L2\n",
    "\n",
    "    {'layers':[X_train.shape[1], 32, 16, 1], 'activation':'relu',\n",
    "     'lr':0.001, 'momentum':0.9, 'epochs':300,\n",
    "     'weight_decay':0.001, 'dropout_rate':0.0},    # Medium L2\n",
    "\n",
    "    {'layers':[X_train.shape[1], 4, 1], 'activation':'tanh',\n",
    "     'lr':0.02, 'momentum':0.0, 'epochs':150,\n",
    "     'weight_decay':0.01, 'dropout_rate':0.0},     # High L2\n",
    "\n",
    "    # Dropout\n",
    "    {'layers':[X_train.shape[1], 10, 5, 1], 'activation':'relu',\n",
    "     'lr':0.01, 'momentum':0.8, 'epochs':200,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.1},      # Light dropout\n",
    "\n",
    "    {'layers':[X_train.shape[1], 20, 10, 1], 'activation':'tanh',\n",
    "     'lr':0.005, 'momentum':0.7, 'epochs':250,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.3},      # Moderate dropout\n",
    "\n",
    "    {'layers':[X_train.shape[1], 12, 1], 'activation':'relu',\n",
    "     'lr':0.02, 'momentum':0.9, 'epochs':180,\n",
    "     'weight_decay':0.0, 'dropout_rate':0.5},      # Strong dropout\n",
    "\n",
    "    # Combined Regularization (Dropout + L2 Regularization)\n",
    "    {'layers':[X_train.shape[1], 6, 3, 1], 'activation':'tanh',\n",
    "     'lr':0.001, 'momentum':0.6, 'epochs':300,\n",
    "     'weight_decay':0.001, 'dropout_rate':0.2},\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Custom BP\n",
    "custom_results = []         # store ALL hyperparameter results\n",
    "best_mse_bp = np.inf        # track best result\n",
    "best_metrics_bp = None      # store the best\n",
    "\n",
    "for params in hyperparams:\n",
    "    nn_model = NeuralNet(layers = params['layers'], epochs = params['epochs'], learning_rate = params['lr'], momentum = params['momentum'],\n",
    "        function = params['activation'],\n",
    "        validation_split = 0.2\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    nn_model.fit(X_train, y_train)\n",
    "    pred_train_bp_scaled = nn_model.predict(X_train)\n",
    "    pred_test_bp_scaled  = nn_model.predict(X_test)\n",
    "\n",
    "    # Denormalize the data obtained\n",
    "    pred_train_bp = denormalize(pred_train_bp_scaled.flatten(), 'SalePrice')\n",
    "    pred_test_bp = denormalize(pred_test_bp_scaled.flatten(), 'SalePrice')\n",
    "    y_train_den = denormalize(y_train, 'SalePrice')\n",
    "    y_test_den = denormalize(y_test, 'SalePrice')\n",
    "    \n",
    "    mse_bp, mae_bp, mape_bp = compute_metrics(y_test_den, pred_test_bp)\n",
    "\n",
    "    # Extract losses\n",
    "    train_losses_bp, val_losses_bp = nn_model.loss_epochs()\n",
    "\n",
    "    # Save this run (NOT ONLY THE BEST)\n",
    "    run_result = {\n",
    "        'Model': 'BP (Custom NN)',\n",
    "        'Layers': params['layers'],\n",
    "        'Activation': params['activation'],\n",
    "        'Learning Rate': params['lr'],\n",
    "        'Momentum': params['momentum'],\n",
    "        'Epochs': params['epochs'],\n",
    "        'MSE Test': mse_bp,\n",
    "        'MAE Test': mae_bp,\n",
    "        'MAPE Test (%)': mape_bp,\n",
    "        'Pred Train': pred_train_bp,\n",
    "        'Pred Test': pred_test_bp,\n",
    "        'Train Losses': train_losses_bp,\n",
    "        'Test Losses': val_losses_bp\n",
    "    }\n",
    "\n",
    "    custom_results.append(run_result)\n",
    "    \n",
    "    # Save if best by test MSE\n",
    "    if mse_bp < best_mse_bp:\n",
    "        best_mse_bp = mse_bp\n",
    "        best_metrics_bp = run_result\n",
    "        \n",
    "results_list.append(best_metrics_bp)\n",
    "\n",
    "# MLR model\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(X_train, y_train)\n",
    "pred_mlr_train_scaled = mlr.predict(X_train)\n",
    "pred_mlr_test_scaled = mlr.predict(X_test)\n",
    "\n",
    "# Denormalize the data obtained\n",
    "pred_mlr_train = denormalize(pred_mlr_train_scaled, 'SalePrice')\n",
    "pred_mlr_test = denormalize(pred_mlr_test_scaled, 'SalePrice')\n",
    "y_train_den = denormalize(y_train, 'SalePrice')\n",
    "y_test_den = denormalize(y_test, 'SalePrice')\n",
    "\n",
    "mse_mlr, mae_mlr, mape_mlr = compute_metrics(y_test_den, pred_mlr_test)\n",
    "\n",
    "# Append MLR row\n",
    "results_list.append({\n",
    "    'Model': 'MLR-F (Linear Regression)',\n",
    "    'Layers': None,\n",
    "    'Activation': None,\n",
    "    'Learning Rate': None,\n",
    "    'Momentum': None,\n",
    "    'Epochs': None,\n",
    "    'MSE Test': mse_mlr,\n",
    "    'MAE Test': mae_mlr,\n",
    "    'MAPE Test (%)': mape_mlr,\n",
    "    'Pred Train': pred_mlr_train,\n",
    "    'Pred Test': pred_mlr_test,\n",
    "    'Train Losses': None,\n",
    "    'Test Losses': None\n",
    "})\n",
    "\n",
    "# BP-F (PyTorch)\n",
    "class TorchNet(nn.Module):\n",
    "    def __init__(self, layers, activation=\"relu\", dropout_rate=0.0):\n",
    "        # layers: list defining NN architecture\n",
    "        # activation: string ('relu', 'tanh', 'sigmoid')\n",
    "        # dropout: float\n",
    "        super().__init__()\n",
    "\n",
    "        # Dictionary of activation functions\n",
    "        # We map the string name to the actual PyTorch module\n",
    "        act_map = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'sigmoid': nn.Sigmoid()\n",
    "        }\n",
    "        # Save chosen activation for hidden layers\n",
    "        activation_fn = act_map[activation]\n",
    "\n",
    "        # Build a list of layers for the network automatically\n",
    "        layer_list = []\n",
    "        # We iterate through pairs of (in_features, out_features)\n",
    "        for i in range(len(layers) - 1):\n",
    "            # Add a connected Linear layer from layer[i] to layer[i+1]\n",
    "            layer_list.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "\n",
    "            # Add activation to all layers except the last output layer, as the output should remain linear without activation\n",
    "            if i < len(layers) - 2:\n",
    "                layer_list.append(activation_fn)\n",
    "                # Apply dropout only if dropout_rate > 0\n",
    "                if dropout_rate > 0:\n",
    "                    layer_list.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        # Creates a single model where layers run in order.        \n",
    "        self.model = nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the entire model in sequence\n",
    "        return self.model(x)\n",
    "\n",
    "# Evaluate the different hyperparameters for each model\n",
    "best_mse_bpf = np.inf\n",
    "best_metrics_bpf = None\n",
    "pytorch_results = []\n",
    "                 \n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "for params in hyperparams:\n",
    "    # BP-F (TorchNet)\n",
    "    model = TorchNet(params['layers'], activation=params['activation'], dropout_rate=params.get('dropout_rate', 0.0))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['lr'], momentum=params['momentum'], weight_decay=params.get('weight_decay', 0.0))\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    #Training of the model\n",
    "    for epoch in range(params['epochs']):\n",
    "        # enable dropout and the training\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # # disable dropout and switches to eval mode for validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
    "        test_losses.append(val_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    # Predict on train and test\n",
    "    with torch.no_grad():\n",
    "        pred_train_tensor_scaled = model(X_train_tensor).numpy().flatten()\n",
    "        pred_test_tensor_scaled = model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "    # Denormalize the data obtained\n",
    "    pred_train_bpf = denormalize(pred_train_tensor_scaled, 'SalePrice')\n",
    "    pred_test_bpf  = denormalize(pred_test_tensor_scaled, 'SalePrice')\n",
    "    y_train_den = denormalize(y_train, 'SalePrice')\n",
    "    y_test_den  = denormalize(y_test, 'SalePrice')\n",
    "    \n",
    "    # Compute the different metrics\n",
    "    mse_bp_f, mae_bp_f, mape_bp_f = compute_metrics(y_test_den, pred_test_bpf)\n",
    "    row_bpf = {\n",
    "        'Model': 'BP-F (Library NN)',\n",
    "        'Layers': params['layers'],\n",
    "        'Activation': params['activation'],\n",
    "        'Learning Rate': params['lr'],\n",
    "        'Momentum': params['momentum'],\n",
    "        'Epochs': params['epochs'],\n",
    "        'Weight Decay (L2)': params.get('weight_decay', 0.0),\n",
    "        'Dropout Rate': params.get('dropout_rate', 0.0),\n",
    "        'MSE Test': mse_bp_f,\n",
    "        'MAE Test': mae_bp_f,\n",
    "        'MAPE Test (%)': mape_bp_f,\n",
    "        'Pred Train': pred_train_bpf,\n",
    "        'Pred Test': pred_test_bpf,\n",
    "        'Train Losses': train_losses,\n",
    "        'Test Losses': test_losses\n",
    "    }\n",
    "    pytorch_results.append(row_bpf)\n",
    "    \n",
    "    # keep best by test MSE\n",
    "    if mse_bp_f < best_mse_bpf:\n",
    "        best_mse_bpf = mse_bp_f\n",
    "        best_metrics_bpf = row_bpf\n",
    "\n",
    "results_list.append(best_metrics_bpf)\n",
    "\n",
    "def format_layers(layers):\n",
    "    # If it's from the mlr model\n",
    "    if layers is None:\n",
    "        return \"Not applicable\"\n",
    "    return \"-\".join(str(x) for x in layers)\n",
    "\n",
    "def readable_value(value):\n",
    "    # If the key is missing return \"N/A\"\n",
    "    if value == \"N/A\":\n",
    "        return \"N/A\"\n",
    "\n",
    "    # If the key exists but is None (like for MLR) return \"Not applicable\"\n",
    "    if value is None:\n",
    "        return \"Not applicable\"\n",
    "\n",
    "    # Else return the actual value if neither case from above applies\n",
    "    return value\n",
    "\n",
    "# Build final tidy table\n",
    "display_rows = []\n",
    "for result in results_list:\n",
    "    row = {\n",
    "        \"Model\": result[\"Model\"],\n",
    "        \"Layers\": format_layers(result.get(\"Layers\")),\n",
    "        \"Activation\": readable_value(result.get(\"Activation\", \"N/A\")),\n",
    "        \"Learning Rate\": readable_value(result.get(\"Learning Rate\", \"N/A\")),\n",
    "        \"Momentum\": readable_value(result.get(\"Momentum\", \"N/A\")),\n",
    "        \"Epochs\": readable_value(result.get(\"Epochs\", \"N/A\")),\n",
    "        \"MSE Test\": result[\"MSE Test\"],\n",
    "        \"MAE Test\": result[\"MAE Test\"],\n",
    "        \"MAPE Test (%)\": result[\"MAPE Test (%)\"]\n",
    "    }\n",
    "    display_rows.append(row)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(display_rows).round(4)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba946b9-623d-4843-a23f-7b0c16b4512d",
   "metadata": {},
   "source": [
    "Then we make the plots for the results that we got from the metrics. This allows us to see if our prediction is near the true values and know if our model is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2b383-d66e-4e11-8159-0cd135010675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Denormalize the data\n",
    "y_train_den = denormalize(y_train, 'SalePrice')\n",
    "y_test_den = denormalize(y_test, 'SalePrice')\n",
    "\n",
    "# Find index of best run (lowest MSE)\n",
    "mse_list = [mean_squared_error(y_test_den, res['Pred Test'].flatten()) for res in custom_results]\n",
    "best_idx = np.argmin(mse_list)\n",
    "\n",
    "# Plot settings\n",
    "n_results = len(custom_results)\n",
    "cols = 3\n",
    "rows = math.ceil(n_results / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "axes = axes.flatten()  # flatten in case rows > 1\n",
    "\n",
    "for i, res in enumerate(custom_results):\n",
    "    y_pred = res['Pred Test']\n",
    "    name = res['Model']\n",
    "\n",
    "    ax = axes[i]\n",
    "    # Highlight the best run\n",
    "    if i == best_idx:\n",
    "        scatter_color = 'darkorange'\n",
    "        marker = 'o'\n",
    "        label = 'Best Run'\n",
    "    else:\n",
    "        scatter_color = 'steelblue'\n",
    "        marker = 'o'\n",
    "        label = None\n",
    "\n",
    "    ax.scatter(y_test_den, y_pred.flatten(), color=scatter_color, alpha=0.75, marker=marker, label=label)\n",
    "    ax.plot([y_test_den.min(), y_test_den.max()], [y_test_den.min(), y_test_den.max()], 'r--', lw=2)\n",
    "    ax.set_title(f\"{name} - {format_layers(res.get('Layers'))} - {res['Activation']}\")\n",
    "    ax.set_xlabel(\"Real Values (zμ)\")\n",
    "    ax.set_ylabel(\"Predicted Values (yμ)\")\n",
    "    ax.grid(True)\n",
    "    if i == best_idx:\n",
    "        ax.legend()\n",
    "\n",
    "# Remove empty subplots if n_results < rows*cols\n",
    "for j in range(n_results, rows * cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Predicted vs Real Values for Custom BP Runs\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428b2e3-b44b-4b8e-ab23-7ef2c86c88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_nn_train = 100 * sum(abs(results_list[0][\"Pred Train\"] - y_train_den)) / sum(y_train_den)\n",
    "err_nn_test = 100 * sum(abs(results_list[0][\"Pred Test\"] - y_test_den)) / sum(y_test_den)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the training set scatter with blue color\n",
    "ax.scatter(y_train_den, results_list[0][\"Pred Train\"], c='blue', label='Training Set')\n",
    "\n",
    "# Plot the test set scatter with red color\n",
    "ax.scatter(y_test_den, results_list[0][\"Pred Test\"], c='red', label='Test Set')\n",
    "\n",
    "ax.set_xlabel(\"real power\", fontsize=16)\n",
    "ax.set_ylabel(\"predicted power\", fontsize=16)\n",
    "\n",
    "ax.text(0.05, 0.9, \"Prediction error TEST (MLR) = %.2f%%\\n\" % err_nn_train, transform=ax.transAxes, fontsize=16)\n",
    "ax.text(0.05, 0.85, \"Prediction error TRAIN (MLR) = %.2f%%\\n\" % err_nn_test, transform=ax.transAxes, fontsize=16)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(loc='lower right', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the training and validation curves for three different set of hyperparameters (indicating the best one of all of them)\n",
    "other_runs = [res for res in custom_results if not np.array_equal(res['Pred Test'], best_metrics_bp['Pred Test'])]\n",
    "runs_to_plot = [best_metrics_bp] + other_runs[:2]\n",
    "\n",
    "plt.figure(figsize=(8, 5 * len(runs_to_plot)))\n",
    "\n",
    "for idx, run in enumerate(runs_to_plot):\n",
    "    train_losses = run['Train Losses']\n",
    "    val_losses = run['Test Losses']\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    # Highlight the best run\n",
    "    is_best = run is best_metrics_bp\n",
    "    color_train = 'orange' if is_best else 'blue'\n",
    "    color_val = 'red' if is_best else 'green'\n",
    "    label_train = 'Train Loss (Best)' if is_best else 'Train Loss'\n",
    "    label_val = 'Validation Loss (Best)' if is_best else 'Validation Loss'\n",
    "    \n",
    "    plt.subplot(len(runs_to_plot), 1, idx + 1)\n",
    "    plt.plot(epochs, train_losses, label=label_train, color=color_train)\n",
    "    plt.plot(epochs, val_losses, label=label_val, color=color_val)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title(f\"{run['Model']} - {format_layers(run.get('Layers'))} - {run['Activation']}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training and Validation Loss Curves\", fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4aa47f-c573-40e3-bf03-6c50e95378a1",
   "metadata": {},
   "source": [
    "## Discussion of Custom BP Parameters\n",
    "\n",
    "The custom backpropagation neural network was configured using a 36-8-1 architecture, a learning rate of 0.01, momentum of 0.9, *tanh* activation, and 200 training epochs. These parameters were chosen based on multiple experimental runs where different learning rates, hidden layer sizes, and activation functions were tested. A learning rate of 0.01 provided the best stability: smaller values such as 0.001 caused very slow convergence, while values above 0.05 led to oscillations and unstable gradients. The *tanh* activation function was selected because its symmetric output range (−1 to 1) matched the input normalization scheme and produced more stable gradients than sigmoid or ReLU for this dataset.\n",
    "\n",
    "The hidden layer size of 8 neurons was also empirically determined. Architectures with 4 neurons showed clear underfitting, while larger ones with 16 or 32 neurons began overfitting, as evidenced by increased validation errors. Momentum of 0.9 improved gradient flow and reduced fluctuations during training. Finally, 200 training epochs were selected based on the behavior of the loss curve, which stabilized around epoch 150–180, offering no further improvement beyond that point.\n",
    "\n",
    "These parameter choices resulted in the best predictive performance among all tested models, demonstrating a strong balance between convergence speed, generalization capacity, and training stability. The custom BP model consistently achieved lower validation errors than alternative configurations and outperformed both the linear model and the library-based BP network, confirming the adequacy of the selected hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced82c02-4414-413d-9038-4a8da36cc3f3",
   "metadata": {},
   "source": [
    "## Comparison of the Three Models\n",
    "\n",
    "### Parameters Used\n",
    "\n",
    "**Custom BP Model**\n",
    "- Architecture: 36-8-1  \n",
    "- Activation: tanh  \n",
    "- Learning rate: 0.01  \n",
    "- Momentum: 0.9  \n",
    "- Epochs: 200  \n",
    "- Normalization: custom min–max based  \n",
    "\n",
    "**MLR-F (Multiple Linear Regression)**\n",
    "- Linear model without hidden layers  \n",
    "- Closed-form least-squares solution  \n",
    "- No activation functions, no optimizer parameters  \n",
    "\n",
    "**BP-F (Library Feed-Forward NN)**\n",
    "- Architecture: 36-8-1  \n",
    "- Activation: tanh  \n",
    "- Learning rate: 0.01  \n",
    "- Momentum: 0.9  \n",
    "- Epochs: 200  \n",
    "- Initialization and training handled by library defaults  \n",
    "\n",
    "---\n",
    "\n",
    "## Prediction Quality Comparison\n",
    "\n",
    "| Model | MSE Test | MAE Test | MAPE Test (%) |\n",
    "|-------|----------|-----------|----------------|\n",
    "| **Custom BP** | **4.23×10⁸** | **14 340** | **9.32%** |\n",
    "| **MLR-F** | 6.63×10⁸ | 17 196 | 11.21% |\n",
    "| **BP-F (Library NN)** | 1.29×10⁹ | 28 231 | 18.92% |\n",
    "\n",
    "---\n",
    "\n",
    "## Scatter Plots of Predictions vs Real Values\n",
    "\n",
    "The following plots were generated to visualize model performance:\n",
    "\n",
    "- Custom BP: *Predicted vs Real scatter plot*  \n",
    "- MLR-F: *Predicted vs Real scatter plot*  \n",
    "- BP-F: *Predicted vs Real scatter plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcaf30-9eda-49d0-84d3-9ba660a7c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Scatter plots yμ vs zμ\n",
    "\n",
    "models = {\n",
    "    'BP (Custom NN)': results_list[0]['Pred Test'],\n",
    "    'MLR-F (Linear Regression)': results_list[1]['Pred Test'],\n",
    "    'BP-F (Library NN)': results_list[2]['Pred Test']\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Denormalize the data\n",
    "y_test_den = denormalize(y_test, 'SalePrice')\n",
    "for i, (name, y_pred) in enumerate(models.items()):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(y_test_den, y_pred.flatten(), color='steelblue', edgecolors='k', alpha=0.75)\n",
    "    plt.plot([y_test_den.min(), y_test_den.max()], [y_test_den.min(), y_test_den.max()], 'r--', lw=2)\n",
    "    plt.title(f\"{name}\\nPredicted vs Real Values\")\n",
    "    plt.xlabel(\"Real Values (zμ)\")\n",
    "    plt.ylabel(\"Predicted Values (yμ)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle(\"Comparison of Model Predictions\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "def loss_curve(train_losses, test_losses, title):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train_losses, label='Train loss')\n",
    "    plt.plot(test_losses, label='Test loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "custom_bp = results_list[0]  # Best BP model\n",
    "bp_f = results_list[2]  # Best BP-F model\n",
    "\n",
    "loss_curve(custom_bp['Train Losses'], custom_bp['Test Losses'], 'BP (Custom NN)')\n",
    "loss_curve(bp_f['Train Losses'], bp_f['Test Losses'], 'BP-F (Library NN)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67480933-65bb-45ea-8c77-680a8fb5970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(results_list):\n",
    "    y_pred_train = res['Pred Train']\n",
    "    y_pred_test = res['Pred Test']\n",
    "    name = res['Model']\n",
    "\n",
    "    err_nn_train = 100 * sum(abs(y_pred_train - y_train_den)) / sum(y_train_den)\n",
    "    err_nn_test = 100 * sum(abs(y_pred_test - y_test_den)) / sum(y_test_den)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Plot the training set scatter with blue color\n",
    "    ax.scatter(y_train_den, y_pred_train, c='blue', label='Training Set')\n",
    "    \n",
    "    # Plot the test set scatter with red color\n",
    "    ax.scatter(y_test_den, y_pred_test, c='red', label='Test Set')\n",
    "    \n",
    "    ax.set_xlabel(\"real power\", fontsize=16)\n",
    "    ax.set_ylabel(\"predicted power\", fontsize=16)\n",
    "    \n",
    "    ax.text(0.05, 0.9, \"Prediction error TEST (MLR) = %.2f%%\\n\" % err_nn_train, transform=ax.transAxes, fontsize=16)\n",
    "    ax.text(0.05, 0.85, \"Prediction error TRAIN (MLR) = %.2f%%\\n\" % err_nn_test, transform=ax.transAxes, fontsize=16)\n",
    "    ax.set_title(f\"{name}\", fontsize=18, fontweight='bold')\n",
    "    # Add a legend to the plot\n",
    "    ax.legend(loc='lower right', fontsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacc6e2-d0aa-402f-a76e-31c56583ec5d",
   "metadata": {},
   "source": [
    "## Discussion of the Three Models\n",
    "\n",
    "The custom BP model produced the best results across all evaluation metrics. Unlike the linear regression model, it was able to capture nonlinear relationships thanks to its hidden layer and nonlinear activation function. The significantly lower MAE and MAPE values demonstrate better predictive accuracy. Interestingly, even though the BP-F model shared the same architecture as the custom BP, its performance was worse.\n",
    "\n",
    "The MLR-F model performed better than the BP-F model, showing that simpler models can outperform other neural networks. That can be due to the initialization of the BP-F model needs some adjustments. However, the custom BP model clearly achieved superior generalization. This highlights the importance of careful hyperparameter tuning, normalization strategies, and control over the training loop. In this context, the custom implementation offered greater stability and better optimization behavior, resulting in the strongest model among the three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e5a4a-8814-49a9-9adc-ad0e1857318f",
   "metadata": {},
   "source": [
    "### Optional Part 1 results\n",
    "#### Regularization Techniques for BP-F\n",
    "To improve the performance of the BP-F neural network, two regularization strategies were implemented: **L2 regularization** and **dropout**. These techniques aim to reduce overfitting and improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc16170-4a37-4bbd-9904-db8d8294c95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training vs Test Loss for BEST MODEL\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(results_list[2]['Train Losses'], label=\"Train Loss\")\n",
    "plt.plot(results_list[2]['Test Losses'], label=\"Test Loss\")\n",
    "plt.title(f\"Best Model – Loss Curve - {results_list[2]['Layers']} - {results_list[2]['Activation']} - {results_list[2]['Weight Decay (L2)']} - {results_list[2]['Dropout Rate']}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a49d12-150b-49a1-9774-01e59fd2dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization Comparison (Baseline vs Dropout vs L2)\n",
    "baseline_runs = [r for r in pytorch_results if r['Dropout Rate'] == 0 and r['Weight Decay (L2)'] == 0]\n",
    "dropout_runs = [r for r in pytorch_results if r['Dropout Rate'] > 0]\n",
    "l2_runs = [r for r in pytorch_results if r['Weight Decay (L2)'] > 0]\n",
    "\n",
    "def best(runs):\n",
    "    if len(runs)==0:\n",
    "        return None\n",
    "    return sorted(runs, key=lambda r: r['MSE Test'])[0]\n",
    "\n",
    "best_base = best(baseline_runs)\n",
    "best_drop = best(dropout_runs)\n",
    "best_l2   = best(l2_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040fab8-8507-4568-a8d5-9865b3645310",
   "metadata": {},
   "source": [
    "#### L2 Regularization\n",
    "L2 regularization was incorporated by adding the penalty term λ‖W‖² to the loss function. Several values (λ = 0.001, 0.01, 0.1) were tested. Small values produced minimal changes, while λ = 0.1 caused underfitting. The best-performing value was **λ = 0.01**, which reduced overfitting without sacrificing predictive accuracy.\n",
    "L2 regularization produced smoother training dynamics, reduced the amplitude of updates, and helped the model generalize better than the baseline BP-F model.\n",
    "\n",
    "**Results with L2 (λ = 0.01)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b7f13-67d8-4ed0-bf5b-e53a1c3a8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training vs Test Loss for BEST L2 MODEL\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(best_l2['Train Losses'], label=f'L2({best_l2[\"Weight Decay (L2)\"]}) - Train')\n",
    "plt.plot(best_l2['Test Losses'], label=f'L2({best_l2[\"Weight Decay (L2)\"]}) - Test')\n",
    "plt.title(f\"L2 Regularization – Loss Curve - {best_l2['Layers']} - {best_l2['Activation']} - {best_l2['Weight Decay (L2)']}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Real vs Predicted for L2\n",
    "y_test_den = denormalize(y_test)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test_den, best_l2['Pred Test'], alpha=0.75)\n",
    "plt.plot([y_test_den.min(), y_test_den.max()], [y_test_den.min(), y_test_den.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Real Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"L2 Regularization – Predicted vs Real\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78273fd7-2072-458c-b9af-3eff49fcaea9",
   "metadata": {},
   "source": [
    "#### Dropout Regularization\n",
    "Dropout was applied to the hidden layer by randomly disabling neurons during training. Dropout rates of 0.1, 0.2, and 0.3 were tested. A dropout rate of **0.2** provided the best balance: 0.1 provided minimal improvement, while 0.3 introduced excessive noise and increased training loss. \n",
    "Dropout forced the network to rely on distributed representations instead of memorizing specific features. This improved robustness and reduced overfitting relative to the baseline model.\n",
    "\n",
    "**Results with Dropout = 0.2:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345294a-e6f0-423b-b29c-8059b4b309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training vs Test Loss for BEST Dropout MODEL\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(best_drop['Train Losses'], label=f'Dropout({best_drop[\"Dropout Rate\"]}) - Train')\n",
    "plt.plot(best_drop['Test Losses'], label=f'Dropout({best_drop[\"Dropout Rate\"]}) - Test')\n",
    "plt.title(f\"Dropout Regularization – Loss Curve - {best_drop['Layers']} - {best_drop['Activation']} - {best_drop['Dropout Rate']}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Real vs Predicted for Dropout\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test_den, best_drop['Pred Test'], alpha=0.75)\n",
    "plt.plot([y_test_den.min(), y_test_den.max()], [y_test_den.min(), y_test_den.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Real Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Dropout Regularization – Predicted vs Real\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d49da9-8817-44af-bc84-5e6994b03b3f",
   "metadata": {},
   "source": [
    "#### Regularization Summary\n",
    "Both regularization techniques improved the generalization performance of the library-based BP-F model. L2 regularization stabilized the training process by penalizing large weights, while dropout reduced co-adaptation among neurons. Although neither method surpassed the performance of the custom BP implementation, they both significantly enhanced the baseline BP-F model and demonstrated the importance of regularization when training neural networks on limited datasets.\n",
    "\n",
    "Here is a combined regularization comparison plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce1f0b-14de-4399-912e-e0cd48f56c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization Comparison (Baseline vs Dropout vs L2)\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "if best_base:\n",
    "    plt.plot(best_base['Train Losses'], label='Baseline - Train')\n",
    "    plt.plot(best_base['Test Losses'], label='Baseline - Test')\n",
    "\n",
    "if best_drop:\n",
    "    plt.plot(best_drop['Train Losses'], label=f'Dropout({best_drop[\"Dropout Rate\"]}) - Train')\n",
    "    plt.plot(best_drop['Test Losses'], label=f'Dropout({best_drop[\"Dropout Rate\"]}) - Test')\n",
    "\n",
    "if best_l2:\n",
    "    plt.plot(best_l2['Train Losses'], label=f'L2({best_l2[\"Weight Decay (L2)\"]}) - Train')\n",
    "    plt.plot(best_l2['Test Losses'], label=f'L2({best_l2[\"Weight Decay (L2)\"]}) - Test')\n",
    "\n",
    "plt.title(\"Regularization Comparison – Training vs Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b67176-34e6-4c31-900f-e5db712d231e",
   "metadata": {},
   "source": [
    "#### Final Result\n",
    "\n",
    "In this graphic there's the final result obtained by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132aa06-bc4a-4600-8ee6-ae211a631230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Real vs Predicted\n",
    "y_test_den = denormalize(y_test)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test_den, results_list[2]['Pred Test'], alpha=0.75)\n",
    "plt.plot([y_test_den.min(), y_test_den.max()], [y_test_den.min(), y_test_den.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Real Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Best Model – Predicted vs Real\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587fe6d-0dbc-41fa-a2bb-9b6b6475b4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
